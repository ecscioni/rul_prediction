{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69629c99",
   "metadata": {},
   "source": [
    "# Predicting Remaining Useful Life (RUL) of Turbofan Engines with the NASA C‑MAPSS FD001 Dataset\n",
    "\n",
    "## 1. Business understanding\n",
    "\n",
    "Predictive maintenance aims to forecast when industrial equipment will fail so that maintenance can be scheduled proactively. For aircraft engines, accurately estimating the **remaining useful life (RUL)** helps airlines plan maintenance, reduce downtime and avoid catastrophic failures. NASA created the **Commercial Modular Aero‑Propulsion System Simulation (C‑MAPSS)** dataset to support research in prognostics and health management.  Each dataset consists of multivariate time‑series from a fleet of simulated turbofan engines that are run until failure.  The FD001 subset used here has 100 training trajectories and 100 test trajectories, one operating condition (sea level) and one fault mode (high‑pressure‑compressor degradation)【932307771945710†L75-L85】.  Each row represents a single operational cycle and includes an engine unit identifier, cycle number, three operational settings and 21 sensor measurements【932307771945710†L68-L73】.  The engines start in a healthy condition and gradually deteriorate; the training sets run until failure whereas the test sets stop before failure.  A separate file contains the true RUL for each test engine【932307771945710†L59-L66】.\n",
    "\n",
    "In this notebook we follow the **CRISP‑DM** (Cross‑Industry Standard Process for Data Mining) framework:\n",
    "\n",
    "1. **Business understanding** – articulate the problem and its value.\n",
    "2. **Data understanding** – explore the structure and quality of the data.\n",
    "3. **Data preparation** – clean and transform the data for modeling.\n",
    "4. **Modeling** – train a random forest regression model to estimate RUL.\n",
    "5. **Evaluation** – assess model performance using appropriate metrics.\n",
    "6. **Deployment / Results** – summarize findings and potential next steps.\n",
    "\n",
    "Citations to the official dataset description and the damage propagation paper are provided throughout to ground the discussion.【932307771945710†L68-L73】【522820073572242†L241-L355】\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec17d10",
   "metadata": {},
   "source": [
    "## 2. Data understanding\n",
    "\n",
    "The FD001 dataset is provided in three text files:\n",
    "\n",
    "- **`train_FD001.txt`** – 100 run‑to‑failure trajectories with 26 space‑separated columns.  The first column is the engine unit number, the second is the cycle index and the next 3 columns are operational settings followed by 21 sensor measurements【932307771945710†L68-L73】.\n",
    "- **`test_FD001.txt`** – 100 partial trajectories that end before failure.\n",
    "- **`RUL_FD001.txt`** – a vector of the true remaining useful life for each test engine.\n",
    "\n",
    "According to the data description, the engines operate under one sea‑level condition and a single fault mode【932307771945710†L75-L85】.  This subset therefore avoids confounding from multiple operating conditions.  Each engine begins at a different initial state due to manufacturing variation and sensor noise, so individual trajectories are not identical.\n",
    "\n",
    "We load the data using `pandas` and assign meaningful column names.  The column list comprises `unit_id`, `time_cycles`, the three operational settings and sensor names `sensor_1` to `sensor_21`.  We compute the RUL for each observation in the training set by subtracting the current cycle from the engine’s maximum cycle.  A higher RUL means more time until failure, while RUL = 0 indicates failure at that cycle【173156099207161†L131-L144】.\n",
    "\n",
    "The code cell below loads and inspects the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5190ae31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T08:23:09.335388Z",
     "iopub.status.busy": "2025-12-15T08:23:09.335176Z",
     "iopub.status.idle": "2025-12-15T08:23:09.704299Z",
     "shell.execute_reply": "2025-12-15T08:23:09.703546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (20631, 27)\n",
      "Test set shape: (13096, 26)\n",
      "\n",
      "First few rows of training data:\n",
      "   unit_id  time_cycles  op_setting_1  op_setting_2  op_setting_3  sensor_1  \\\n",
      "0        1            1       -0.0007       -0.0004         100.0    518.67   \n",
      "1        1            2        0.0019       -0.0003         100.0    518.67   \n",
      "2        1            3       -0.0043        0.0003         100.0    518.67   \n",
      "3        1            4        0.0007        0.0000         100.0    518.67   \n",
      "4        1            5       -0.0019       -0.0002         100.0    518.67   \n",
      "\n",
      "   sensor_2  sensor_3  sensor_4  sensor_5  ...  sensor_13  sensor_14  \\\n",
      "0    641.82   1589.70   1400.60     14.62  ...    2388.02    8138.62   \n",
      "1    642.15   1591.82   1403.14     14.62  ...    2388.07    8131.49   \n",
      "2    642.35   1587.99   1404.20     14.62  ...    2388.03    8133.23   \n",
      "3    642.35   1582.79   1401.87     14.62  ...    2388.08    8133.83   \n",
      "4    642.37   1582.85   1406.22     14.62  ...    2388.04    8133.80   \n",
      "\n",
      "   sensor_15  sensor_16  sensor_17  sensor_18  sensor_19  sensor_20  \\\n",
      "0     8.4195       0.03        392       2388      100.0      39.06   \n",
      "1     8.4318       0.03        392       2388      100.0      39.00   \n",
      "2     8.4178       0.03        390       2388      100.0      38.95   \n",
      "3     8.3682       0.03        392       2388      100.0      38.88   \n",
      "4     8.4294       0.03        393       2388      100.0      38.90   \n",
      "\n",
      "   sensor_21  RUL  \n",
      "0    23.4190  191  \n",
      "1    23.4236  190  \n",
      "2    23.3442  189  \n",
      "3    23.3739  188  \n",
      "4    23.4044  187  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Summary of maximum cycles per engine in training set:\n",
      "count    100.000000\n",
      "mean     206.310000\n",
      "std       46.342749\n",
      "min      128.000000\n",
      "25%      177.000000\n",
      "50%      199.000000\n",
      "75%      229.250000\n",
      "max      362.000000\n",
      "Name: time_cycles, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to dataset files\n",
    "DATA_PATH = '/home/oai/share'\n",
    "\n",
    "# Column names: unit id, time cycles, 3 operational settings, 21 sensors\n",
    "columns = ['unit_id', 'time_cycles', 'op_setting_1', 'op_setting_2', 'op_setting_3'] + [f'sensor_{i}' for i in range(1, 22)]\n",
    "\n",
    "# Load the training, test and RUL files\n",
    "train = pd.read_csv(f'{DATA_PATH}/train_FD001.txt', sep=r'\\s+', header=None, names=columns)\n",
    "test = pd.read_csv(f'{DATA_PATH}/test_FD001.txt', sep=r'\\s+', header=None, names=columns)\n",
    "rul_test = pd.read_csv(f'{DATA_PATH}/RUL_FD001.txt', sep=r'\\s+', header=None, names=['RUL'])\n",
    "\n",
    "# Compute RUL for training data: RUL = max_cycle - current_cycle per engine\n",
    "train['RUL'] = train.groupby('unit_id')['time_cycles'].transform(lambda x: x.max() - x)\n",
    "\n",
    "# Peek at the data\n",
    "print('Training set shape:', train.shape)\n",
    "print('Test set shape:', test.shape)\n",
    "print('')\n",
    "print('First few rows of training data:')\n",
    "print(train.head())\n",
    "print('')\n",
    "\n",
    "# Summary: number of cycles per engine\n",
    "cycles_summary = train.groupby('unit_id')['time_cycles'].max().describe()\n",
    "print('Summary of maximum cycles per engine in training set:')\n",
    "print(cycles_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc58f58",
   "metadata": {},
   "source": [
    "## 3. Data preparation\n",
    "\n",
    "### 3.1 Feature selection\n",
    "\n",
    "Some sensors may provide little or no useful information for degradation because they remain constant across all cycles.  Following common practice, we compute the variance of each sensor across the training set and remove sensors with variance below a threshold (0.01)【173156099207161†L154-L161】.\n",
    "\n",
    "### 3.2 Feature scaling\n",
    "\n",
    "Because the sensors measure different physical quantities (e.g., temperatures in °R and pressures in psia) their ranges differ widely【173156099207161†L175-L184】.  To ensure that the model treats each variable fairly, we apply min‑max scaling to the operational settings and sensor features, fitting the scaler on the training data and applying it to both training and test sets.\n",
    "\n",
    "The following code performs feature selection and scaling, and prepares `X_train`, `y_train` for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2ac8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T08:23:09.708188Z",
     "iopub.status.busy": "2025-12-15T08:23:09.707961Z",
     "iopub.status.idle": "2025-12-15T08:23:10.181130Z",
     "shell.execute_reply": "2025-12-15T08:23:10.179654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 10 constant/low‑variance sensors: ['sensor_1', 'sensor_5', 'sensor_6', 'sensor_8', 'sensor_10', 'sensor_13', 'sensor_15', 'sensor_16', 'sensor_18', 'sensor_19']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Identify sensor columns\n",
    "sensor_cols = [col for col in train.columns if col.startswith('sensor_')]\n",
    "\n",
    "# Drop sensors with very low variance (< 0.01)\n",
    "variances = train[sensor_cols].var()\n",
    "drop_sensors = variances[variances < 0.01].index.tolist()\n",
    "\n",
    "print(f'Dropping {len(drop_sensors)} constant/low‑variance sensors: {drop_sensors}')\n",
    "\n",
    "# Prepare feature columns: operational settings + remaining sensors\n",
    "feature_cols = ['op_setting_1', 'op_setting_2', 'op_setting_3'] + [c for c in sensor_cols if c not in drop_sensors]\n",
    "\n",
    "# Initialize MinMaxScaler and fit on training data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = train.copy()\n",
    "test_scaled = test.copy()\n",
    "\n",
    "train_scaled[feature_cols] = scaler.fit_transform(train[feature_cols])\n",
    "test_scaled[feature_cols] = scaler.transform(test[feature_cols])\n",
    "\n",
    "# Prepare training features and target\n",
    "X_train = train_scaled[feature_cols]\n",
    "y_train = train_scaled['RUL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefda6bc",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "We choose a **Random Forest Regressor** to estimate the remaining useful life.  Random forests are ensemble models that average the predictions of multiple decision trees; they can capture nonlinear relationships and handle correlated features.  We split the training data into a training set and a validation set, train the model and evaluate its performance using root‑mean‑squared error (RMSE) and mean absolute error (MAE).  Cross‑validation could also be used but is computationally expensive with a large dataset.\n",
    "\n",
    "The code below fits the model and evaluates it on a hold‑out validation set.  We also compute predictions for the test set and compare them against the provided `RUL_FD001.txt` values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c3e11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T08:23:10.184142Z",
     "iopub.status.busy": "2025-12-15T08:23:10.183858Z",
     "iopub.status.idle": "2025-12-15T08:23:17.780009Z",
     "shell.execute_reply": "2025-12-15T08:23:17.779102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 41.6561\n",
      "Validation MAE: 29.8038\n",
      "Test set results (comparing predicted RUL on last cycle vs true RUL):\n",
      "Test RMSE: 34.0676\n",
      "Test MAE: 25.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pyvenv/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/opt/pyvenv/lib/python3.11/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Split into train and validation sets\n",
    "data_X = X_train\n",
    "data_y = y_train\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(data_X, data_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "rf_model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_val = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "rmse = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "mae = mean_absolute_error(y_val, y_pred_val)\n",
    "print(f'Validation RMSE: {rmse:.4f}')\n",
    "print(f'Validation MAE: {mae:.4f}')\n",
    "\n",
    "# Predict RUL for the last cycle of each engine in the test set\n",
    "# For each engine we take only its last row (latest time_cycles)\n",
    "test_last_cycles = test_scaled.groupby('unit_id').tail(1)\n",
    "X_test_last = test_last_cycles[feature_cols]\n",
    "\n",
    "# Predict RUL on test data\n",
    "y_test_pred = rf_model.predict(X_test_last)\n",
    "\n",
    "# Compare with true RUL\n",
    "true_rul = rul_test['RUL'].values\n",
    "\n",
    "rmse_test = mean_squared_error(true_rul, y_test_pred, squared=False)\n",
    "mae_test = mean_absolute_error(true_rul, y_test_pred)\n",
    "print('Test set results (comparing predicted RUL on last cycle vs true RUL):')\n",
    "print(f'Test RMSE: {rmse_test:.4f}')\n",
    "print(f'Test MAE: {mae_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bb8e7",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "The random forest model achieves a validation RMSE and MAE that indicate how closely the predicted RUL matches the actual values in the hold‑out set.  On the test set, we evaluate the model by comparing predictions for the last available cycle of each engine to the true RUL provided in `RUL_FD001.txt`.  These metrics help assess whether the model can generalize to unseen engines.\n",
    "\n",
    "A future improvement would be to perform k‑fold cross‑validation and tune hyperparameters (number of trees, maximum depth, minimum samples per leaf) to improve accuracy.  Feature engineering (e.g., constructing trend‑based features or using sequences) may also boost performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612624b2",
   "metadata": {},
   "source": [
    "## 6. Deployment / Conclusion\n",
    "\n",
    "This notebook followed the CRISP‑DM methodology to build a predictive maintenance model for turbofan engines using NASA’s C‑MAPSS FD001 data.  We described the business value of estimating remaining useful life, explored the structure of the data, prepared it by removing low‑variance sensors and scaling features, and trained a random forest regressor.  Evaluation on a validation set and the provided test RUL values demonstrated reasonable predictive performance.\n",
    "\n",
    "In a production setting, such a model could be integrated into a maintenance management system to alert engineers when an engine is approaching end‑of‑life, enabling proactive maintenance.  Further work could involve using more sophisticated models (e.g., gradient boosting, deep learning), incorporating temporal sequence features and performing rigorous hyperparameter tuning.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
