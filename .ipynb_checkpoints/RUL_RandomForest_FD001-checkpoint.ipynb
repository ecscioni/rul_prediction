{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fc41d9",
   "metadata": {},
   "source": [
    "# Remaining Useful Life (RUL) prediction — Random Forest (scikit-learn)\n",
    "\n",
    "This notebook reproduces the *workflow* of the Medium tutorial (RUL on NASA CMAPSS FD001) without copying the article verbatim.\n",
    "\n",
    "Data source: NASA CMAPSS “Jet Engine Simulated Data” (FD001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you see \"ModuleNotFoundError\", run this cell once, then restart the kernel.\n",
    "%pip install -U numpy pandas matplotlib seaborn scikit-learn ipython requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0edb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:.3f}\")\n",
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0fe50d",
   "metadata": {},
   "source": [
    "## 1) Quick toy example (what “RUL” means visually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ee4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [60, 63, 67, 74, 77, 81, 82, 87, 92]\n",
    "B = [92, 99, 104, 110, 116, 125]\n",
    "C = np.append(np.repeat(np.nan, len(A) - 1), B)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(A, linewidth=3)\n",
    "plt.plot(C, linestyle=\":\", linewidth=3)\n",
    "plt.axvline(x=len(A)-1, linestyle=\":\", linewidth=3)\n",
    "plt.axvline(x=len(C)-1, linestyle=\":\", linewidth=3)\n",
    "plt.title(\"Example sensor series (observe: recorded part vs unknown future)\")\n",
    "plt.xlabel(\"# cycles\")\n",
    "plt.ylabel(\"sensor value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719549c",
   "metadata": {},
   "source": [
    "## 2) Download + load NASA CMAPSS FD001\n",
    "\n",
    "This will download the NASA CMAPSS zip, extract it, and load:\n",
    "- `train_FD001.txt`\n",
    "- `test_FD001.txt`\n",
    "- `RUL_FD001.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DATA_DIR = Path(\"data_cmapss\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "zip_path = DATA_DIR / \"CMAPSSData.zip\"\n",
    "\n",
    "# NASA dataset landing page lists CMAPSSData.zip (FD001–FD004 inside).\n",
    "# If this direct download fails in your environment, download manually from NASA Open Data Portal\n",
    "# and place the zip at: data_cmapss/CMAPSSData.zip\n",
    "NASA_ZIP_URL = \"https://data.nasa.gov/api/views/ff5v-kuh6/files/CMAPSSData.zip?download=1\"\n",
    "\n",
    "if not zip_path.exists():\n",
    "    print(\"Downloading CMAPSSData.zip ...\")\n",
    "    r = requests.get(NASA_ZIP_URL, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    zip_path.write_bytes(r.content)\n",
    "    print(\"Saved:\", zip_path)\n",
    "else:\n",
    "    print(\"Zip already present:\", zip_path)\n",
    "\n",
    "# Extract\n",
    "extract_dir = DATA_DIR / \"CMAPSSData\"\n",
    "if not extract_dir.exists():\n",
    "    extract_dir.mkdir(exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "        zf.extractall(extract_dir)\n",
    "    print(\"Extracted to:\", extract_dir)\n",
    "else:\n",
    "    print(\"Already extracted:\", extract_dir)\n",
    "\n",
    "train_txt = extract_dir / \"train_FD001.txt\"\n",
    "test_txt  = extract_dir / \"test_FD001.txt\"\n",
    "rul_txt   = extract_dir / \"RUL_FD001.txt\"\n",
    "\n",
    "(train_txt.exists(), test_txt.exists(), rul_txt.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names (unit, cycle, 3 operational settings, 21 sensors)\n",
    "cols = (\n",
    "    [\"unit\", \"cycles\", \"op_setting1\", \"op_setting2\", \"op_setting3\"]\n",
    "    + [f\"s{i}\" for i in range(1, 22)]\n",
    ")\n",
    "\n",
    "def read_cmapss_txt(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", header=None, engine=\"python\")\n",
    "    # Some CMAPSS files end up with extra empty columns depending on parsing.\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "    df.columns = cols[: df.shape[1]]\n",
    "    return df\n",
    "\n",
    "train = read_cmapss_txt(train_txt)\n",
    "test  = read_cmapss_txt(test_txt)\n",
    "RUL_true = pd.read_csv(rul_txt, header=None, names=[\"RUL\"])\n",
    "\n",
    "train.shape, test.shape, RUL_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6c719",
   "metadata": {},
   "source": [
    "Optional: write the same CSV names used in many tutorials (`RUL_train.csv`, `RUL_test.csv`, `RUL_target.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(DATA_DIR / \"RUL_train.csv\", index=False)\n",
    "test.to_csv(DATA_DIR / \"RUL_test.csv\", index=False)\n",
    "RUL_true.to_csv(DATA_DIR / \"RUL_target.csv\", index=False)\n",
    "print(\"Wrote:\", DATA_DIR / \"RUL_train.csv\")\n",
    "print(\"Wrote:\", DATA_DIR / \"RUL_test.csv\")\n",
    "print(\"Wrote:\", DATA_DIR / \"RUL_target.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e58510e",
   "metadata": {},
   "source": [
    "## 3) Basic inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca58d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train:\", train.shape)\n",
    "print(\"test :\", test.shape)\n",
    "print(\"RUL  :\", RUL_true.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values check\n",
    "train.isna().sum().head(10), test.isna().sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36279b4f",
   "metadata": {},
   "source": [
    "## 4) Remove flat-line sensors (constant columns)\n",
    "\n",
    "A quick way is: columns with std == 0 in the train set.\n",
    "Many FD001 tutorials drop: s1, s5, s10, s16, s18, s19 and op_setting3.\n",
    "We’ll compute constant columns automatically, then drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [c for c in train.columns if c not in [\"unit\"]]\n",
    "const_cols = [c for c in numeric_cols if train[c].std() == 0]\n",
    "const_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bfc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.drop(columns=const_cols).copy()\n",
    "test2  = test.drop(columns=const_cols).copy()\n",
    "\n",
    "train2.shape, test2.shape, const_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c9f4f",
   "metadata": {},
   "source": [
    "### Distributions (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c10a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.hist(bins=50, figsize=(16, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.hist(bins=50, figsize=(16, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a060ad",
   "metadata": {},
   "source": [
    "## 5) Maximum cycles per unit (train vs test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9eb6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cycles_train = train2.groupby(\"unit\", as_index=False)[\"cycles\"].max()\n",
    "max_cycles_test  = test2.groupby(\"unit\", as_index=False)[\"cycles\"].max()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.bar(max_cycles_train[\"unit\"], max_cycles_train[\"cycles\"])\n",
    "plt.ylim(0, 400)\n",
    "plt.title(\"Train: max cycles per unit\")\n",
    "plt.xlabel(\"unit\")\n",
    "plt.ylabel(\"max cycles\")\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.bar(max_cycles_test[\"unit\"], max_cycles_test[\"cycles\"])\n",
    "plt.ylim(0, 400)\n",
    "plt.title(\"Test: max cycles per unit\")\n",
    "plt.xlabel(\"unit\")\n",
    "plt.ylabel(\"max cycles\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97ff20",
   "metadata": {},
   "source": [
    "## 6) Data preparation\n",
    "\n",
    "1) Create Time-To-Failure (TTF) for each train row.  \n",
    "2) Scale the feature columns with MinMaxScaler (fit on train, transform on test).  \n",
    "3) Convert TTF to a fraction per unit: 1.0 at start → 0.0 at failure.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 TTF in cycles for training rows\n",
    "train3 = train2.merge(\n",
    "    train2.groupby(\"unit\", as_index=False)[\"cycles\"].max().rename(columns={\"cycles\": \"maxcycles\"}),\n",
    "    on=\"unit\",\n",
    "    how=\"left\",\n",
    ")\n",
    "train3[\"TTF\"] = train3[\"maxcycles\"] - train3[\"cycles\"]\n",
    "\n",
    "train3[[\"unit\",\"cycles\",\"maxcycles\",\"TTF\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779147ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Scaling (fit on train, apply to test)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# choose columns to scale: everything except identifiers and targets we create later\n",
    "cols_to_scale = [c for c in train3.columns if c not in [\"unit\", \"cycles\", \"maxcycles\", \"TTF\"]]\n",
    "\n",
    "train_scaled = train3.copy()\n",
    "test_scaled  = test2.copy()\n",
    "\n",
    "train_scaled[cols_to_scale] = scaler.fit_transform(train_scaled[cols_to_scale])\n",
    "test_scaled[cols_to_scale]  = scaler.transform(test_scaled[cols_to_scale])\n",
    "\n",
    "train_scaled[cols_to_scale].describe().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d426d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Fraction TTF per unit: fTTF = TTF / max(TTF) per unit\n",
    "# (vectorized with groupby transform)\n",
    "train_scaled[\"fTTF\"] = train3[\"TTF\"] / train3.groupby(\"unit\")[\"TTF\"].transform(\"max\")\n",
    "train_scaled[\"fTTF\"] = train_scaled[\"fTTF\"].clip(0, 1)\n",
    "\n",
    "train_scaled[[\"unit\",\"cycles\",\"TTF\",\"fTTF\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7206f76",
   "metadata": {},
   "source": [
    "## 7) Build X/y for model training\n",
    "\n",
    "We’ll predict the *fraction* (fTTF).  \n",
    "Features: cycles + scaled operational settings + scaled sensor columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"cycles\"] + cols_to_scale  # exclude 'unit'\n",
    "X_train = train_scaled[feature_cols].to_numpy()\n",
    "y_train = train_scaled[\"fTTF\"].to_numpy()\n",
    "\n",
    "X_test  = test_scaled[feature_cols].to_numpy()\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d554d",
   "metadata": {},
   "source": [
    "## 8) Model: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81baac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=1337,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Optional quick cross-val (R^2). Comment out if too slow.\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=3)\n",
    "print(\"CV R^2:\", scores, \"mean=\", scores.mean().round(4))\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a380dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict fraction for every row in the test set\n",
    "score_frac = rf.predict(X_test)\n",
    "score_frac.min(), score_frac.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b03bb70",
   "metadata": {},
   "source": [
    "## 9) Convert predicted fraction back to RUL (cycles)\n",
    "\n",
    "Idea:\n",
    "- fraction = remaining / total  → total ≈ cycles / (1 - fraction)\n",
    "- predicted RUL at the last observed cycle = predicted_total_cycles - maxcycles_observed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d644cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test2.copy()\n",
    "\n",
    "# add max observed cycles per unit\n",
    "test_pred = test_pred.merge(\n",
    "    test_pred.groupby(\"unit\", as_index=False)[\"cycles\"].max().rename(columns={\"cycles\": \"maxcycles\"}),\n",
    "    on=\"unit\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# attach per-row fraction predictions\n",
    "test_pred[\"score_frac\"] = score_frac\n",
    "\n",
    "# avoid divide-by-zero if a prediction is 1.0\n",
    "eps = 1e-6\n",
    "safe_frac = np.clip(test_pred[\"score_frac\"].to_numpy(), 0.0, 1.0 - eps)\n",
    "\n",
    "test_pred[\"pred_total_cycles\"] = test_pred[\"cycles\"] / (1.0 - safe_frac)\n",
    "test_pred[\"pred_RUL_row\"] = test_pred[\"pred_total_cycles\"] - test_pred[\"maxcycles\"]\n",
    "\n",
    "test_pred[[\"unit\",\"cycles\",\"maxcycles\",\"score_frac\",\"pred_total_cycles\",\"pred_RUL_row\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d53a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single predicted RUL per engine: take the last row for each unit\n",
    "pred_RUL_per_unit = (\n",
    "    test_pred.sort_values([\"unit\",\"cycles\"])\n",
    "            .groupby(\"unit\", as_index=False)\n",
    "            .tail(1)[[\"unit\",\"pred_RUL_row\"]]\n",
    "            .sort_values(\"unit\")\n",
    ")\n",
    "\n",
    "pred_RUL_per_unit[\"pred_RUL\"] = pred_RUL_per_unit[\"pred_RUL_row\"].round().astype(int)\n",
    "pred_RUL_per_unit.head(), pred_RUL_per_unit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc251e",
   "metadata": {},
   "source": [
    "## 10) Evaluate vs true RUL (FD001)\n",
    "\n",
    "NASA provides `RUL_FD001.txt` (one value per test unit).  \n",
    "We compare our per-unit prediction against those true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = RUL_true[\"RUL\"].to_numpy()\n",
    "y_pred = pred_RUL_per_unit[\"pred_RUL\"].to_numpy()\n",
    "\n",
    "print(\"R^2  :\", round(metrics.r2_score(y_true, y_pred), 4))\n",
    "print(\"RMSE :\", round(np.sqrt(metrics.mean_squared_error(y_true, y_pred)), 3))\n",
    "print(\"MAE  :\", round(metrics.mean_absolute_error(y_true, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f92c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(y_true, label=\"true\")\n",
    "plt.plot(y_pred, label=\"pred\")\n",
    "plt.xlabel(\"test unit\")\n",
    "plt.ylabel(\"RUL (cycles)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ff2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = y_pred - y_true\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(diff, bins=26, edgecolor=\"black\")\n",
    "plt.axvline(0, linestyle=\"--\")\n",
    "plt.title(\"Prediction error distribution (pred - true)\")\n",
    "plt.xlabel(\"cycles\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"count\": [(diff < 0).sum(), (diff == 0).sum(), (diff > 0).sum()]\n",
    "}, index=[\"smaller\",\"zero\",\"larger\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12587c8b",
   "metadata": {},
   "source": [
    "## 11) Feature importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d45af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "order = np.argsort(importances)[::-1]\n",
    "\n",
    "top_n = 15\n",
    "for i in order[:top_n]:\n",
    "    print(f\"{feature_cols[i]:<15}  {importances[i]*100:6.2f}%\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
